{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "beee05e9",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf4a9bc-18a2-45c5-aa29-68e7d903d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from predict import Wav2Vec2Aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b498993a-f2d7-490b-81c5-ce5ebd64d8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some necessary variables\n",
    "\n",
    "# Define input data and result paths\n",
    "# Modify these variables if you want the model to read and write data to different paths\n",
    "DATA_PATH = '../data'\n",
    "RESULT_PATH = '../result'\n",
    "SONGS_PATH = os.path.join(DATA_PATH, 'songs')\n",
    "LYRICS_PATH = os.path.join(DATA_PATH, 'lyrics')\n",
    "GROUNDTRUTH_LYRICS_PATH = os.path.join(DATA_PATH, 'groundtruth')\n",
    "TIME_SUBMISSION_PATH = os.path.join(RESULT_PATH, 'time_submission.csv')\n",
    "JUPYTER_SUBMISSION_PATH = os.path.join(RESULT_PATH, 'jupyter_submission.zip')\n",
    "\n",
    "LYRICS_FILE_EXTENSION = 'json'\n",
    "MODEL_PATH = 'not-tanh/wav2vec2-large-xlsr-53-vietnamese'\n",
    "\n",
    "# Ensure result directory is created\n",
    "if not os.path.exists(RESULT_PATH):\n",
    "    os.makedirs(RESULT_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f4194b6",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ce429ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mdnam\\.local\\opt\\miniconda\\envs\\zac\\lib\\site-packages\\transformers\\configuration_utils.py:369: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blank Token id [PAD]/<pad> 106\n"
     ]
    }
   ],
   "source": [
    "model = Wav2Vec2Aligner(MODEL_PATH, cuda=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3de03e92",
   "metadata": {},
   "source": [
    "# Read test cases and run predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adb6a3e2",
   "metadata": {},
   "source": [
    "**Note**: The model in this notebook is evaluated on a subset of the training set (100 samples or 10%) provided by the Zalo AI Challenge host since (1) the size of the training set is large and (2) it takes considerable amount of time to infer on each sample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdedaa4-a83c-49c8-a88d-d59a5397ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test cases\n",
    "test_cases = []\n",
    "num_test_cases = 100\n",
    "\n",
    "for song_file in random.sample(os.listdir(SONGS_PATH), num_test_cases):\n",
    "    filename = song_file.split('.')[0]\n",
    "    lyrics_file = os.path.join(LYRICS_PATH, f'{filename}.{LYRICS_FILE_EXTENSION}')\n",
    "    \n",
    "    with open(lyrics_file, 'r', encoding='utf-8') as f:\n",
    "        label = json.load(f)\n",
    "\n",
    "        lyric = []\n",
    "        num_words_per_sentence = []\n",
    "        for sentence in label:\n",
    "            num_words = 0\n",
    "            for word in sentence['l']:\n",
    "                lyric.append(word['d'])\n",
    "                num_words += 1\n",
    "            num_words_per_sentence.append(num_words)\n",
    "\n",
    "        test_cases.append(\n",
    "            {\n",
    "                \"sent\": lyric,\n",
    "                \"num_words\": num_words_per_sentence,\n",
    "                \"wav_path\": os.path.join(SONGS_PATH, song_file),\n",
    "                \"out_path\": os.path.join(RESULT_PATH, filename + '.json')\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe475090-db58-48a4-8230-e9537770f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "WARNING:tensorflow:From c:\\Users\\mdnam\\.local\\opt\\miniconda\\envs\\zac\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:561: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models\\2stems\\model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [24:42<00:00, 14.83s/it] \n"
     ]
    }
   ],
   "source": [
    "# Run prediction\n",
    "prediction_times = []\n",
    "for i, item in enumerate(tqdm(test_cases)):\n",
    "    t1 = time()\n",
    "    model.align_single_sample(item)\n",
    "    t2 = time()\n",
    "\n",
    "    file_name = os.path.basename(item['wav_path'])\n",
    "    prediction_time = int(t2 * 1000 - t1 * 1000)\n",
    "    \n",
    "    prediction_times.append((file_name, prediction_time))\n",
    "\n",
    "time_submission_df = pd.DataFrame(data=prediction_times, columns=['fname', 'time'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8f38cf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>38313731345f3333.wav</td>\n",
       "      <td>12780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38313239375f3635.wav</td>\n",
       "      <td>12236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3132313739305f3131.wav</td>\n",
       "      <td>16472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38313332385f3539.wav</td>\n",
       "      <td>7469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38313136385f313434.wav</td>\n",
       "      <td>4716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>37333439365f3238.wav</td>\n",
       "      <td>9975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>37333531325f3233.wav</td>\n",
       "      <td>10252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>38313338385f313338.wav</td>\n",
       "      <td>6671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>39323838395f3137.wav</td>\n",
       "      <td>18077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>38313633315f3234.wav</td>\n",
       "      <td>15400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     fname   time\n",
       "0     38313731345f3333.wav  12780\n",
       "1     38313239375f3635.wav  12236\n",
       "2   3132313739305f3131.wav  16472\n",
       "3     38313332385f3539.wav   7469\n",
       "4   38313136385f313434.wav   4716\n",
       "..                     ...    ...\n",
       "95    37333439365f3238.wav   9975\n",
       "96    37333531325f3233.wav  10252\n",
       "97  38313338385f313338.wav   6671\n",
       "98    39323838395f3137.wav  18077\n",
       "99    38313633315f3234.wav  15400\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_submission_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3993a1e5",
   "metadata": {},
   "source": [
    "# Evaluate and save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3d66abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some helper functions\n",
    "\n",
    "def predict_to_df(filepath):\n",
    "    f = open(filepath,  encoding=\"utf8\")\n",
    "    label = json.load(f)\n",
    "    columns = ['d', 's', 'e', 'key', 'sentences']\n",
    "    dfs = []\n",
    "    # df = pd.DataFrame(columns = ['d', 's', 'e', 'key', 'sentences'])\n",
    "    sen_index = 0\n",
    "    word_index = 0\n",
    "    for sen in label:\n",
    "        for word in sen['l']:\n",
    "            d = word['d']\n",
    "            s = word['s']\n",
    "            e = word['e']\n",
    "            dfs.append([d, s, e, d+str(word_index), sen_index])\n",
    "            # df = df.append({'d':d, 's':s, 'e':e, 'key':d+str(word_index), 'sentences':sen_index}, ignore_index=True)\n",
    "            word_index += 1\n",
    "        sen_index += 1\n",
    "    f.close()\n",
    "    dfs = pd.DataFrame(dfs, columns = columns)\n",
    "    return dfs\n",
    "\n",
    "def label_to_df(filepath):\n",
    "    f = open(filepath,  encoding=\"utf8\")\n",
    "    label = json.load(f)\n",
    "    # df = pd.DataFrame(columns = ['d', 's', 'e', 'key', 'sentences'])\n",
    "    columns = ['d', 's', 'e', 'key', 'sentences']\n",
    "    dfs = []\n",
    "    sen_index = 0\n",
    "    word_index = 0\n",
    "    for sen in label:\n",
    "        for word in sen['l']:\n",
    "            d = word['d']\n",
    "            s = word['s']\n",
    "            e = word['e']\n",
    "            dfs.append([d, s, e, d+str(word_index), sen_index])\n",
    "            # df = df.append({'d':d, 's':s, 'e':e, 'key':d+str(word_index), 'sentences':sen_index}, ignore_index=True)\n",
    "            word_index += 1\n",
    "        sen_index += 1\n",
    "    f.close()\n",
    "    dfs = pd.DataFrame(dfs, columns = columns)\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a118ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(label_dir, predict_dir, filename):\n",
    "    # config path file\n",
    "    label_path = os.path.join(label_dir, filename + '.json')\n",
    "    predict_path = os.path.join(predict_dir, filename + '.json')\n",
    "    # read data\n",
    "    df_predict = predict_to_df(predict_path)\n",
    "    df_label = label_to_df(label_path)\n",
    "    \n",
    "    # calculate\n",
    "    df_join = pd.merge(left=df_label, right=df_predict, on='key', how='left')\n",
    "    df_join = df_join.fillna(0) #     fill na elements\n",
    "    df_join['s_min'] = np.where((df_join['s_x'] >= df_join['s_y']), df_join['s_y'], df_join['s_x'])\n",
    "    df_join['e_max'] = np.where((df_join['e_x'] >= df_join['e_y']), df_join['e_x'], df_join['e_y'])\n",
    "    df_join['union'] = df_join['e_max'] - df_join['s_min']\n",
    "    df_join['inter'] = df_join['union'] - np.abs(df_join['s_x']-df_join['s_y']) - np.abs(df_join['e_x']-df_join['e_y'])\n",
    "    df_join['inter'] = np.where(df_join['inter']<0, 0, df_join['inter'])\n",
    "    # add 1 to avoid error\n",
    "    df_join['iou'] = np.round(df_join['inter']/(df_join['union']+1),2)\n",
    "    \n",
    "    # iou by sentence\n",
    "    iou_by_sen = df_join.groupby(['sentences_x'])['iou'].mean()\n",
    "    # iou total\n",
    "    final_iou = iou_by_sen.mean()\n",
    "    return iou_by_sen, final_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65e809e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IoU: 0.45202038221738716\n"
     ]
    }
   ],
   "source": [
    "# Evaluation against groundtruth lyrics\n",
    "\n",
    "iou_segments = []\n",
    "for test_case in test_cases:\n",
    "    file_id = os.path.basename(test_case['wav_path']).replace('.wav', '')\n",
    "    iou_sentence, iou_segment = IoU(GROUNDTRUTH_LYRICS_PATH, RESULT_PATH, file_id)\n",
    "    iou_segments.append(iou_segment)\n",
    "\n",
    "print(f'IoU: {np.mean(iou_segments)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60a596f6-b975-4354-aae1-0de99e3c7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prediction time\n",
    "time_submission_df.to_csv(\n",
    "    TIME_SUBMISSION_PATH,\n",
    "    index=False, # Don't save index\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zac",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "be6e78b967a4387a5bf3a20f39c271e466431bb6690e4719a06e78c187174835"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
